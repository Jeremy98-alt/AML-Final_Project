{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stdrr/AML-Final_Project/blob/main/code/baseline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8LzuJnDUJsO"
      },
      "source": [
        "# **CondLaneNet: a Top-to-down Lane Detection Framework Based on Conditional Convolution**\n",
        "\n",
        "[Official GitHub repository](https://github.com/aliyun/conditional-lane-detection)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd data\n",
        "# train & validation data (~10 GB)\n",
        "%mkdir tusimple\n",
        "!wget \"https://s3.us-east-2.amazonaws.com/benchmark-frontend/datasets/1/train_set.zip\"\n",
        "!unzip train_set.zip -d tusimple\n",
        "# test images (~10 GB)\n",
        "%mkdir tusimple-test\n",
        "!wget \"https://s3.us-east-2.amazonaws.com/benchmark-frontend/datasets/1/test_set.zip\"\n",
        "!unzip test_set.zip -d tusimple-test\n",
        "# test annotations\n",
        "!wget \"https://s3.us-east-2.amazonaws.com/benchmark-frontend/truth/1/test_label.json\" -P tusimple-test/"
      ],
      "metadata": {
        "id": "nZRVuRE3UVe1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "At3RoutDUdmQ"
      },
      "source": [
        "## Connect Google Drive and set working folder\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W-yW4UjYUpEd",
        "outputId": "0914c3c0-a23e-4ae4-e812-3049b56acee6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1j8Q1dPfU0HB",
        "outputId": "183a8f8b-a6c1-46da-eecd-59164269637b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/gdrive/.shortcut-targets-by-id/1bKkOxnV3HlM0klPcoIk5ik84I4xDxYs7/AML-Final_Project\n"
          ]
        }
      ],
      "source": [
        "%cd /gdrive/MyDrive/University/Second_year/AML/AML-Final_Project"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install the dependencies"
      ],
      "metadata": {
        "id": "WSoPC2K7GzQD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pillow==7.1.2"
      ],
      "metadata": {
        "id": "uBELE0dPHeas"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd code/conditional-lane-detection/"
      ],
      "metadata": {
        "id": "XlM2a4OaGt9c",
        "outputId": "b02a79f1-a174-4a32-fd27-2d225aee5d42",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/gdrive/.shortcut-targets-by-id/1bKkOxnV3HlM0klPcoIk5ik84I4xDxYs7/AML-Final_Project/code/conditional-lane-detection\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements/build.txt"
      ],
      "metadata": {
        "id": "tkkl3E2hHN0x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python setup.py develop"
      ],
      "metadata": {
        "id": "R1h85CxhIWnq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run the model"
      ],
      "metadata": {
        "id": "NFsDOdoxTqdm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python tools/train.py configs/condlanenet/culane/culane_small_train.py --work_dir "
      ],
      "metadata": {
        "id": "_bvmCwzIQFij",
        "outputId": "647c2773-d854-428c-cf89-e8922cff844e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021-12-07 20:56:47,649 - mmdet - INFO - Environment info:\n",
            "------------------------------------------------------------\n",
            "sys.platform: linux\n",
            "Python: 3.7.12 (default, Sep 10 2021, 00:21:48) [GCC 7.5.0]\n",
            "CUDA available: True\n",
            "CUDA_HOME: /usr/local/cuda\n",
            "NVCC: Build cuda_11.1.TC455_06.29190527_0\n",
            "GPU 0: Tesla K80\n",
            "GCC: gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\n",
            "PyTorch: 1.10.0+cu111\n",
            "PyTorch compiling details: PyTorch built with:\n",
            "  - GCC 7.3\n",
            "  - C++ Version: 201402\n",
            "  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\n",
            "  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)\n",
            "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
            "  - LAPACK is enabled (usually provided by MKL)\n",
            "  - NNPACK is enabled\n",
            "  - CPU capability usage: AVX2\n",
            "  - CUDA Runtime 11.1\n",
            "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86\n",
            "  - CuDNN 8.0.5\n",
            "  - Magma 2.5.2\n",
            "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, \n",
            "\n",
            "TorchVision: 0.11.1+cu111\n",
            "OpenCV: 4.1.2\n",
            "MMCV: 0.5.6\n",
            "MMDetection: 2.0.0+c57b242\n",
            "MMDetection Compiler: GCC 7.5\n",
            "MMDetection CUDA Compiler: 11.1\n",
            "------------------------------------------------------------\n",
            "\n",
            "2021-12-07 20:56:47,650 - mmdet - INFO - Distributed training: False\n",
            "2021-12-07 20:56:48,656 - mmdet - INFO - Config:\n",
            "dataset_type = 'CulaneDataset'\n",
            "data_root = '../../data/culane'\n",
            "mask_down_scale = 8\n",
            "hm_down_scale = 16\n",
            "num_lane_classes = 1\n",
            "line_width = 3\n",
            "radius = 6\n",
            "nms_thr = 4\n",
            "batch_size = 4\n",
            "img_norm_cfg = dict(\n",
            "    mean=[75.3, 76.6, 77.6], std=[50.5, 53.8, 54.3], to_rgb=False)\n",
            "ori_scale = (1640, 590)\n",
            "crop_bbox = [0, 270, 1640, 590]\n",
            "img_scale = (800, 320)\n",
            "mask_size = (1, 40, 100)\n",
            "train_cfg = dict(out_scale=8)\n",
            "test_cfg = dict(out_scale=8)\n",
            "model = dict(\n",
            "    type='CondLaneNet',\n",
            "    pretrained='torchvision://resnet18',\n",
            "    train_cfg=dict(out_scale=8),\n",
            "    test_cfg=dict(out_scale=8),\n",
            "    num_classes=1,\n",
            "    backbone=dict(\n",
            "        type='ResNet',\n",
            "        depth=18,\n",
            "        strides=(1, 2, 2, 2),\n",
            "        num_stages=4,\n",
            "        out_indices=(0, 1, 2, 3),\n",
            "        frozen_stages=1,\n",
            "        norm_cfg=dict(type='BN', requires_grad=True),\n",
            "        norm_eval=True,\n",
            "        style='pytorch'),\n",
            "    neck=dict(\n",
            "        type='TransConvFPN',\n",
            "        in_channels=[128, 256, 64],\n",
            "        out_channels=64,\n",
            "        num_outs=3,\n",
            "        trans_idx=-1,\n",
            "        trans_cfg=dict(\n",
            "            in_dim=512,\n",
            "            attn_in_dims=[512, 64],\n",
            "            attn_out_dims=[64, 64],\n",
            "            strides=[1, 1],\n",
            "            ratios=[4, 4],\n",
            "            pos_shape=(4, 10, 25))),\n",
            "    head=dict(\n",
            "        type='CondLaneHead',\n",
            "        heads=dict(hm=1),\n",
            "        in_channels=(64, ),\n",
            "        num_classes=1,\n",
            "        head_channels=64,\n",
            "        head_layers=1,\n",
            "        disable_coords=False,\n",
            "        branch_in_channels=64,\n",
            "        branch_channels=64,\n",
            "        branch_out_channels=64,\n",
            "        reg_branch_channels=64,\n",
            "        branch_num_conv=1,\n",
            "        hm_idx=1,\n",
            "        mask_idx=0,\n",
            "        compute_locations_pre=True,\n",
            "        location_configs=dict(size=(4, 1, 40, 100), device='cuda:0')),\n",
            "    loss_weights=dict(\n",
            "        hm_weight=1, kps_weight=0.4, row_weight=1.0, range_weight=1.0))\n",
            "train_compose = dict(bboxes=False, keypoints=True, masks=False)\n",
            "train_al_pipeline = [\n",
            "    dict(\n",
            "        type='Compose', params=dict(bboxes=False, keypoints=True,\n",
            "                                    masks=False)),\n",
            "    dict(type='Crop', x_min=0, x_max=1640, y_min=270, y_max=590, p=1),\n",
            "    dict(type='Resize', height=320, width=800, p=1),\n",
            "    dict(\n",
            "        type='OneOf',\n",
            "        transforms=[\n",
            "            dict(\n",
            "                type='RGBShift',\n",
            "                r_shift_limit=10,\n",
            "                g_shift_limit=10,\n",
            "                b_shift_limit=10,\n",
            "                p=1.0),\n",
            "            dict(\n",
            "                type='HueSaturationValue',\n",
            "                hue_shift_limit=(-10, 10),\n",
            "                sat_shift_limit=(-15, 15),\n",
            "                val_shift_limit=(-10, 10),\n",
            "                p=1.0)\n",
            "        ],\n",
            "        p=0.7),\n",
            "    dict(type='JpegCompression', quality_lower=85, quality_upper=95, p=0.2),\n",
            "    dict(\n",
            "        type='OneOf',\n",
            "        transforms=[\n",
            "            dict(type='Blur', blur_limit=3, p=1.0),\n",
            "            dict(type='MedianBlur', blur_limit=3, p=1.0)\n",
            "        ],\n",
            "        p=0.2),\n",
            "    dict(type='RandomBrightness', limit=0.2, p=0.6),\n",
            "    dict(\n",
            "        type='ShiftScaleRotate',\n",
            "        shift_limit=0.1,\n",
            "        scale_limit=(-0.2, 0.2),\n",
            "        rotate_limit=10,\n",
            "        border_mode=0,\n",
            "        p=0.6),\n",
            "    dict(\n",
            "        type='RandomResizedCrop',\n",
            "        height=320,\n",
            "        width=800,\n",
            "        scale=(0.8, 1.2),\n",
            "        ratio=(1.7, 2.7),\n",
            "        p=0.6),\n",
            "    dict(type='Resize', height=320, width=800, p=1)\n",
            "]\n",
            "val_al_pipeline = [\n",
            "    dict(\n",
            "        type='Compose', params=dict(bboxes=False, keypoints=True,\n",
            "                                    masks=False)),\n",
            "    dict(type='Crop', x_min=0, x_max=1640, y_min=270, y_max=590, p=1),\n",
            "    dict(type='Resize', height=320, width=800, p=1)\n",
            "]\n",
            "train_pipeline = [\n",
            "    dict(\n",
            "        type='albumentation',\n",
            "        pipelines=[\n",
            "            dict(\n",
            "                type='Compose',\n",
            "                params=dict(bboxes=False, keypoints=True, masks=False)),\n",
            "            dict(type='Crop', x_min=0, x_max=1640, y_min=270, y_max=590, p=1),\n",
            "            dict(type='Resize', height=320, width=800, p=1),\n",
            "            dict(\n",
            "                type='OneOf',\n",
            "                transforms=[\n",
            "                    dict(\n",
            "                        type='RGBShift',\n",
            "                        r_shift_limit=10,\n",
            "                        g_shift_limit=10,\n",
            "                        b_shift_limit=10,\n",
            "                        p=1.0),\n",
            "                    dict(\n",
            "                        type='HueSaturationValue',\n",
            "                        hue_shift_limit=(-10, 10),\n",
            "                        sat_shift_limit=(-15, 15),\n",
            "                        val_shift_limit=(-10, 10),\n",
            "                        p=1.0)\n",
            "                ],\n",
            "                p=0.7),\n",
            "            dict(\n",
            "                type='JpegCompression',\n",
            "                quality_lower=85,\n",
            "                quality_upper=95,\n",
            "                p=0.2),\n",
            "            dict(\n",
            "                type='OneOf',\n",
            "                transforms=[\n",
            "                    dict(type='Blur', blur_limit=3, p=1.0),\n",
            "                    dict(type='MedianBlur', blur_limit=3, p=1.0)\n",
            "                ],\n",
            "                p=0.2),\n",
            "            dict(type='RandomBrightness', limit=0.2, p=0.6),\n",
            "            dict(\n",
            "                type='ShiftScaleRotate',\n",
            "                shift_limit=0.1,\n",
            "                scale_limit=(-0.2, 0.2),\n",
            "                rotate_limit=10,\n",
            "                border_mode=0,\n",
            "                p=0.6),\n",
            "            dict(\n",
            "                type='RandomResizedCrop',\n",
            "                height=320,\n",
            "                width=800,\n",
            "                scale=(0.8, 1.2),\n",
            "                ratio=(1.7, 2.7),\n",
            "                p=0.6),\n",
            "            dict(type='Resize', height=320, width=800, p=1)\n",
            "        ]),\n",
            "    dict(\n",
            "        type='Normalize',\n",
            "        mean=[75.3, 76.6, 77.6],\n",
            "        std=[50.5, 53.8, 54.3],\n",
            "        to_rgb=False),\n",
            "    dict(type='DefaultFormatBundle'),\n",
            "    dict(\n",
            "        type='CollectLane',\n",
            "        down_scale=8,\n",
            "        hm_down_scale=16,\n",
            "        max_mask_sample=5,\n",
            "        line_width=3,\n",
            "        radius=6,\n",
            "        keys=['img', 'gt_hm'],\n",
            "        meta_keys=[\n",
            "            'filename', 'sub_img_name', 'gt_masks', 'mask_shape', 'hm_shape',\n",
            "            'ori_shape', 'img_shape', 'down_scale', 'hm_down_scale',\n",
            "            'img_norm_cfg', 'gt_points'\n",
            "        ])\n",
            "]\n",
            "val_pipeline = [\n",
            "    dict(\n",
            "        type='albumentation',\n",
            "        pipelines=[\n",
            "            dict(\n",
            "                type='Compose',\n",
            "                params=dict(bboxes=False, keypoints=True, masks=False)),\n",
            "            dict(type='Crop', x_min=0, x_max=1640, y_min=270, y_max=590, p=1),\n",
            "            dict(type='Resize', height=320, width=800, p=1)\n",
            "        ]),\n",
            "    dict(\n",
            "        type='Normalize',\n",
            "        mean=[75.3, 76.6, 77.6],\n",
            "        std=[50.5, 53.8, 54.3],\n",
            "        to_rgb=False),\n",
            "    dict(type='DefaultFormatBundle'),\n",
            "    dict(\n",
            "        type='CollectLane',\n",
            "        down_scale=8,\n",
            "        hm_down_scale=16,\n",
            "        radius=6,\n",
            "        keys=['img', 'gt_hm'],\n",
            "        meta_keys=[\n",
            "            'filename', 'sub_img_name', 'gt_masks', 'mask_shape', 'hm_shape',\n",
            "            'ori_shape', 'img_shape', 'down_scale', 'hm_down_scale',\n",
            "            'img_norm_cfg', 'gt_points'\n",
            "        ])\n",
            "]\n",
            "data = dict(\n",
            "    samples_per_gpu=4,\n",
            "    workers_per_gpu=8,\n",
            "    train=dict(\n",
            "        type='CulaneDataset',\n",
            "        data_root='../../data/culane',\n",
            "        data_list='../../data/culane/list/train.txt',\n",
            "        pipeline=[\n",
            "            dict(\n",
            "                type='albumentation',\n",
            "                pipelines=[\n",
            "                    dict(\n",
            "                        type='Compose',\n",
            "                        params=dict(bboxes=False, keypoints=True,\n",
            "                                    masks=False)),\n",
            "                    dict(\n",
            "                        type='Crop',\n",
            "                        x_min=0,\n",
            "                        x_max=1640,\n",
            "                        y_min=270,\n",
            "                        y_max=590,\n",
            "                        p=1),\n",
            "                    dict(type='Resize', height=320, width=800, p=1),\n",
            "                    dict(\n",
            "                        type='OneOf',\n",
            "                        transforms=[\n",
            "                            dict(\n",
            "                                type='RGBShift',\n",
            "                                r_shift_limit=10,\n",
            "                                g_shift_limit=10,\n",
            "                                b_shift_limit=10,\n",
            "                                p=1.0),\n",
            "                            dict(\n",
            "                                type='HueSaturationValue',\n",
            "                                hue_shift_limit=(-10, 10),\n",
            "                                sat_shift_limit=(-15, 15),\n",
            "                                val_shift_limit=(-10, 10),\n",
            "                                p=1.0)\n",
            "                        ],\n",
            "                        p=0.7),\n",
            "                    dict(\n",
            "                        type='JpegCompression',\n",
            "                        quality_lower=85,\n",
            "                        quality_upper=95,\n",
            "                        p=0.2),\n",
            "                    dict(\n",
            "                        type='OneOf',\n",
            "                        transforms=[\n",
            "                            dict(type='Blur', blur_limit=3, p=1.0),\n",
            "                            dict(type='MedianBlur', blur_limit=3, p=1.0)\n",
            "                        ],\n",
            "                        p=0.2),\n",
            "                    dict(type='RandomBrightness', limit=0.2, p=0.6),\n",
            "                    dict(\n",
            "                        type='ShiftScaleRotate',\n",
            "                        shift_limit=0.1,\n",
            "                        scale_limit=(-0.2, 0.2),\n",
            "                        rotate_limit=10,\n",
            "                        border_mode=0,\n",
            "                        p=0.6),\n",
            "                    dict(\n",
            "                        type='RandomResizedCrop',\n",
            "                        height=320,\n",
            "                        width=800,\n",
            "                        scale=(0.8, 1.2),\n",
            "                        ratio=(1.7, 2.7),\n",
            "                        p=0.6),\n",
            "                    dict(type='Resize', height=320, width=800, p=1)\n",
            "                ]),\n",
            "            dict(\n",
            "                type='Normalize',\n",
            "                mean=[75.3, 76.6, 77.6],\n",
            "                std=[50.5, 53.8, 54.3],\n",
            "                to_rgb=False),\n",
            "            dict(type='DefaultFormatBundle'),\n",
            "            dict(\n",
            "                type='CollectLane',\n",
            "                down_scale=8,\n",
            "                hm_down_scale=16,\n",
            "                max_mask_sample=5,\n",
            "                line_width=3,\n",
            "                radius=6,\n",
            "                keys=['img', 'gt_hm'],\n",
            "                meta_keys=[\n",
            "                    'filename', 'sub_img_name', 'gt_masks', 'mask_shape',\n",
            "                    'hm_shape', 'ori_shape', 'img_shape', 'down_scale',\n",
            "                    'hm_down_scale', 'img_norm_cfg', 'gt_points'\n",
            "                ])\n",
            "        ],\n",
            "        test_mode=False),\n",
            "    val=dict(\n",
            "        type='CulaneDataset',\n",
            "        data_root='../../data/culane',\n",
            "        data_list='../../data/culane/list/test.txt',\n",
            "        pipeline=[\n",
            "            dict(\n",
            "                type='albumentation',\n",
            "                pipelines=[\n",
            "                    dict(\n",
            "                        type='Compose',\n",
            "                        params=dict(bboxes=False, keypoints=True,\n",
            "                                    masks=False)),\n",
            "                    dict(\n",
            "                        type='Crop',\n",
            "                        x_min=0,\n",
            "                        x_max=1640,\n",
            "                        y_min=270,\n",
            "                        y_max=590,\n",
            "                        p=1),\n",
            "                    dict(type='Resize', height=320, width=800, p=1)\n",
            "                ]),\n",
            "            dict(\n",
            "                type='Normalize',\n",
            "                mean=[75.3, 76.6, 77.6],\n",
            "                std=[50.5, 53.8, 54.3],\n",
            "                to_rgb=False),\n",
            "            dict(type='DefaultFormatBundle'),\n",
            "            dict(\n",
            "                type='CollectLane',\n",
            "                down_scale=8,\n",
            "                hm_down_scale=16,\n",
            "                radius=6,\n",
            "                keys=['img', 'gt_hm'],\n",
            "                meta_keys=[\n",
            "                    'filename', 'sub_img_name', 'gt_masks', 'mask_shape',\n",
            "                    'hm_shape', 'ori_shape', 'img_shape', 'down_scale',\n",
            "                    'hm_down_scale', 'img_norm_cfg', 'gt_points'\n",
            "                ])\n",
            "        ],\n",
            "        test_mode=False),\n",
            "    test=dict(\n",
            "        type='CulaneDataset',\n",
            "        data_root='../../data/culane',\n",
            "        data_list='../../data/culane/list/test.txt',\n",
            "        test_suffix='.jpg',\n",
            "        pipeline=[\n",
            "            dict(\n",
            "                type='albumentation',\n",
            "                pipelines=[\n",
            "                    dict(\n",
            "                        type='Compose',\n",
            "                        params=dict(bboxes=False, keypoints=True,\n",
            "                                    masks=False)),\n",
            "                    dict(\n",
            "                        type='Crop',\n",
            "                        x_min=0,\n",
            "                        x_max=1640,\n",
            "                        y_min=270,\n",
            "                        y_max=590,\n",
            "                        p=1),\n",
            "                    dict(type='Resize', height=320, width=800, p=1)\n",
            "                ]),\n",
            "            dict(\n",
            "                type='Normalize',\n",
            "                mean=[75.3, 76.6, 77.6],\n",
            "                std=[50.5, 53.8, 54.3],\n",
            "                to_rgb=False),\n",
            "            dict(type='DefaultFormatBundle'),\n",
            "            dict(\n",
            "                type='CollectLane',\n",
            "                down_scale=8,\n",
            "                hm_down_scale=16,\n",
            "                radius=6,\n",
            "                keys=['img', 'gt_hm'],\n",
            "                meta_keys=[\n",
            "                    'filename', 'sub_img_name', 'gt_masks', 'mask_shape',\n",
            "                    'hm_shape', 'ori_shape', 'img_shape', 'down_scale',\n",
            "                    'hm_down_scale', 'img_norm_cfg', 'gt_points'\n",
            "                ])\n",
            "        ],\n",
            "        test_mode=True))\n",
            "optimizer = dict(type='Adam', lr=0.0003, betas=(0.9, 0.999), eps=1e-08)\n",
            "optimizer_config = dict(grad_clip=None)\n",
            "lr_config = dict(\n",
            "    policy='step',\n",
            "    warmup='constant',\n",
            "    warmup_iters=100,\n",
            "    warmup_ratio=0.3333333333333333,\n",
            "    step=[8, 14])\n",
            "checkpoint_config = dict(interval=1)\n",
            "log_config = dict(interval=1, hooks=[dict(type='TextLoggerHook')])\n",
            "total_epochs = 16\n",
            "device_ids = '0,1'\n",
            "dist_params = dict(backend='nccl')\n",
            "log_level = 'INFO'\n",
            "work_dir = './work_dirs/exps/culane/small'\n",
            "load_from = None\n",
            "resume_from = None\n",
            "workflow = [('train', 200), ('val', 1)]\n",
            "gpu_ids = range(0, 1)\n",
            "\n",
            "/gdrive/.shortcut-targets-by-id/1bKkOxnV3HlM0klPcoIk5ik84I4xDxYs7/AML-Final_Project/code/conditional-lane-detection/mmdet/models/necks/trans_fpn.py:44: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  dim_t = self.temperature**(2 * (dim_t // 2) / self.num_pos_feats)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "2021-12-07 20:56:58,159 - root - INFO - load model from: torchvision://resnet18\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100% 44.7M/44.7M [00:00<00:00, 77.3MB/s]\n",
            "2021-12-07 20:56:58,958 - mmdet - WARNING - The model and loaded state dict do not match exactly\n",
            "\n",
            "unexpected key in source state_dict: fc.weight, fc.bias\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "2021-12-07 20:57:01,173 - mmdet - INFO - Start running, host: root@eeaf3fa87626, work_dir: /gdrive/.shortcut-targets-by-id/1bKkOxnV3HlM0klPcoIk5ik84I4xDxYs7/AML-Final_Project/code/conditional-lane-detection/work_dirs/exps/culane/small\n",
            "2021-12-07 20:57:01,173 - mmdet - INFO - workflow: [('train', 200), ('val', 1)], max: 16 epochs\n",
            "Traceback (most recent call last):\n",
            "  File \"tools/train.py\", line 159, in <module>\n",
            "    main()\n",
            "  File \"tools/train.py\", line 155, in main\n",
            "    meta=meta)\n",
            "  File \"/gdrive/.shortcut-targets-by-id/1bKkOxnV3HlM0klPcoIk5ik84I4xDxYs7/AML-Final_Project/code/conditional-lane-detection/mmdet/apis/train.py\", line 165, in train_detector\n",
            "    runner.run(data_loaders, cfg.workflow, cfg.total_epochs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/mmcv/runner/runner.py\", line 383, in run\n",
            "    epoch_runner(data_loaders[i], **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/mmcv/runner/runner.py\", line 278, in train\n",
            "    for i, data_batch in enumerate(data_loader):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 521, in __next__\n",
            "    data = self._next_data()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1203, in _next_data\n",
            "    return self._process_data(data)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1229, in _process_data\n",
            "    data.reraise()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/_utils.py\", line 434, in reraise\n",
            "    raise exception\n",
            "AttributeError: Caught AttributeError in DataLoader worker process 0.\n",
            "Original Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/worker.py\", line 287, in _worker_loop\n",
            "    data = fetcher.fetch(index)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n",
            "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\", line 49, in <listcomp>\n",
            "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "  File \"/gdrive/.shortcut-targets-by-id/1bKkOxnV3HlM0klPcoIk5ik84I4xDxYs7/AML-Final_Project/code/conditional-lane-detection/mmdet/datasets/custom.py\", line 140, in __getitem__\n",
            "    data = self.prepare_train_img(idx)\n",
            "  File \"/gdrive/.shortcut-targets-by-id/1bKkOxnV3HlM0klPcoIk5ik84I4xDxYs7/AML-Final_Project/code/conditional-lane-detection/mmdet/datasets/culane_dataset.py\", line 66, in prepare_train_img\n",
            "    ori_shape = img.shape\n",
            "AttributeError: 'NoneType' object has no attribute 'shape'\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "_-NbPuCIlsCm"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "J-Hx64g0WpWp"
      ],
      "name": "AML-Final.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}